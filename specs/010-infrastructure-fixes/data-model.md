# Data Model: Critical Infrastructure Fixes

**Feature**: 010-infrastructure-fixes
**Date**: 2025-11-12
**Status**: Design Phase

## Overview

This document defines the data entities and their relationships for the three infrastructure fixes:
- Export Job Status Tracking (Redis-based temporary storage)
- Export Request Validation (schema and rules)
- Re-ID Similarity Analysis (read-only analysis of existing data)

---

## Entity Definitions

### 1. Export Job Status (Redis)

**Purpose**: Track background export task completion status with automatic expiry.

**Storage**: Redis with 1-hour TTL (temporary, not persisted to PostgreSQL)

**Key Format**: `export_job:{job_id}`
- `job_id`: UUID generated by Celery when task is queued

**Value Format**: JSON string

```json
{
  "status": "processing|completed|failed",
  "filename": "report_20251112_143022.pdf",
  "download_url": "/api/static/exports/report_20251112_143022.pdf",
  "completed_at": "2025-11-12T14:30:45Z",
  "error": "Optional error message if status=failed"
}
```

**Fields**:

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| status | enum | YES | Current job state: "processing", "completed", "failed" |
| filename | string | NO | Generated filename (present when status=completed) |
| download_url | string | NO | Relative URL for file download (present when status=completed) |
| completed_at | ISO8601 | NO | UTC timestamp when job finished (present when status=completed or failed) |
| error | string | NO | Error message (present only when status=failed) |

**State Transitions**:
```
START -> processing (API creates job)
        |
        v
    completed (worker succeeds) -> [TTL expires after 1 hour] -> DELETED
        |
        v
    failed (worker error) -> [TTL expires after 1 hour] -> DELETED
```

**TTL Behavior**:
- Set when worker writes status (SETEX command)
- Duration: 3600 seconds (1 hour)
- Automatic cleanup by Redis when TTL expires
- GET after expiry returns null (API interprets as 404)

**Error Handling**:
- Redis connection failure: Worker logs error but completes task
- Missing job_id: API returns 404 "Job not found or expired"
- Malformed JSON: API catches exception, returns 500

---

### 2. Export Request (API Input Schema)

**Purpose**: Validate user-submitted export parameters before queueing worker task.

**Storage**: Not persisted (validation only, discarded after queuing or rejection)

**Schema**: Pydantic models (PDFExportRequest, ZIPExportRequest)

#### PDFExportRequest

```python
from pydantic import BaseModel, validator
from datetime import date

class PDFExportRequest(BaseModel):
    start_date: date
    end_date: date
    group_by: str  # "day", "week", or "month"

    @validator('group_by')
    def validate_group_by(cls, v):
        if v not in ['day', 'week', 'month']:
            raise ValueError('group_by must be one of: day, week, month')
        return v
```

**Validation Rules** (enforced in API endpoint):

| Rule ID | Rule | Error Message | HTTP Status |
|---------|------|---------------|-------------|
| VR-001 | start_date < end_date | "start_date must be before end_date" | 400 |
| VR-002 | (end_date - start_date).days <= 365 | "Date range cannot exceed 1 year" | 400 |
| VR-003 | group_by in ["day", "week", "month"] | "group_by must be one of: day, week, month" | 400 |
| VR-004 | start_date <= today() | "start_date cannot be in the future" | 400 |

**Validation Order**:
1. Pydantic validates types (date fields are dates, group_by is string)
2. Pydantic validator checks group_by against allowed values
3. Endpoint logic validates multi-field rules (VR-001, VR-002, VR-004)
4. If all pass: queue Celery task and return 202
5. If any fail: raise HTTPException with 400 status and clear message

**Example Valid Request**:
```json
{
  "start_date": "2023-09-01",
  "end_date": "2024-01-31",
  "group_by": "month"
}
```

**Example Invalid Requests**:
```json
{
  "start_date": "2024-12-31",
  "end_date": "2024-01-01",
  "group_by": "day"
}
// Fails VR-001: start_date > end_date

{
  "start_date": "2020-01-01",
  "end_date": "2025-01-01",
  "group_by": "week"
}
// Fails VR-002: range is 1827 days > 365

{
  "start_date": "2024-01-01",
  "end_date": "2024-06-01",
  "group_by": "hour"
}
// Fails VR-003: "hour" not in allowed values

{
  "start_date": "2026-01-01",
  "end_date": "2026-12-31",
  "group_by": "month"
}
// Fails VR-004: start_date in future (assuming current year 2025)
```

#### ZIPExportRequest

**Structure**: Same as PDFExportRequest (identical validation rules)

```python
class ZIPExportRequest(BaseModel):
    start_date: date
    end_date: date
    group_by: str

    # Same validators as PDFExportRequest
```

**Rationale for Duplication**:
- Allows future divergence (PDF might add chart_type, ZIP might add compression_level)
- Clear separation in OpenAPI documentation
- Type safety in endpoint signatures

---

### 3. Re-ID Similarity Score (Analysis Entity)

**Purpose**: Analyze re-identification matching performance by examining similarity scores.

**Storage**: PostgreSQL (existing data in `detections` table)

**Table**: `detections` (already exists, no schema changes)

**Relevant Fields**:

| Field | Type | Description |
|-------|------|-------------|
| id | UUID | Detection primary key |
| deer_id | UUID (nullable) | Assigned deer profile (null if unassigned) |
| feature_vector | vector(512) | pgvector embedding for Re-ID |
| classification | enum | Detection class: buck, doe, fawn, etc. |
| confidence | float | ML model confidence (0.0-1.0) |
| image_id | UUID | Parent image reference |
| created_at | timestamp | When detection was created |

**Analysis Query Pattern**:
```sql
-- Count assigned vs unassigned
SELECT
    CASE WHEN deer_id IS NOT NULL THEN 'assigned' ELSE 'unassigned' END as status,
    COUNT(*) as count
FROM detections
WHERE classification IN ('buck', 'doe', 'fawn')
GROUP BY status;

-- Compute pairwise similarity for analysis
-- (Performed in Python using feature_vector comparisons)
```

**Similarity Calculation** (in Python analysis script):
```python
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

# Load feature vectors
detection_vectors = [d.feature_vector for d in detections]
deer_vectors = [d.feature_vector for d in deer_profiles]

# Compute similarity matrix
similarities = cosine_similarity(detection_vectors, deer_vectors)

# Similarity score: 0.0 (completely different) to 1.0 (identical)
# Current threshold: 0.70
# Assignment rate: (detections with similarity >= 0.70) / total * 100
```

**Analysis Metrics**:

| Metric | Formula | Current Value | Target |
|--------|---------|---------------|--------|
| Assignment Rate | (assigned_count / total_count) * 100 | 9.5% (1,100 / 11,570) | 20%+ |
| Unassigned Rate | (unassigned_count / total_count) * 100 | 90.5% (10,470 / 11,570) | <80% |
| False Positive Rate | (incorrect_assignments / assigned_count) * 100 | Unknown (needs manual validation) | <5% |

**Threshold Testing**:
- Test values: 0.70 (current), 0.65, 0.60, 0.55
- For each threshold: calculate assignment rate
- Goal: Find threshold that maximizes assignment rate while keeping false positive rate <5%

**Analysis Output**:
```json
{
  "current_threshold": 0.70,
  "current_assignment_rate": 9.5,
  "total_detections": 11570,
  "assigned_detections": 1100,
  "deer_profiles": 20,
  "threshold_analysis": [
    {
      "threshold": 0.70,
      "assignment_rate": 9.5,
      "expected_assigned": 1100,
      "recommendation": "current"
    },
    {
      "threshold": 0.65,
      "assignment_rate": 14.2,
      "expected_assigned": 1643,
      "recommendation": "moderate improvement"
    },
    {
      "threshold": 0.60,
      "assignment_rate": 22.8,
      "expected_assigned": 2638,
      "recommendation": "significant improvement (verify false positives)"
    },
    {
      "threshold": 0.55,
      "assignment_rate": 35.1,
      "expected_assigned": 4061,
      "recommendation": "high risk of false positives"
    }
  ],
  "recommendation": {
    "optimal_threshold": 0.60,
    "predicted_improvement": "2.4x increase (9.5% -> 22.8%)",
    "next_steps": "Manual validation of 100 sample assignments at 0.60 threshold"
  }
}
```

---

## Entity Relationships

### Export Job Status <-> Celery Task
- **Relationship**: 1-to-1
- **Key**: Celery task_id is used as job_id in Redis key
- **Lifecycle**: Created when worker starts, deleted by TTL after 1 hour
- **Access Pattern**: API reads, worker writes

### Export Request <-> Export Job Status
- **Relationship**: 1-to-1 (if validation passes)
- **Flow**:
  1. User submits ExportRequest to API
  2. API validates request (if fails: return 400, no job created)
  3. API queues Celery task (task_id generated)
  4. API returns 202 with job_id (same as task_id)
  5. Worker executes, writes status to Redis using job_id
  6. User polls GET /api/exports/pdf/{job_id} to read status

### Re-ID Similarity <-> Detections/Deer
- **Relationship**: Many-to-Many (each detection compared to multiple deer)
- **Join**: Not stored persistently, computed on-demand for analysis
- **Access Pattern**: Read-only queries, no writes during analysis

---

## Data Flow Diagrams

### Export Job Status Tracking (Option A)

```
[User] --POST /api/exports/pdf--> [API Endpoint]
                                        |
                                        v
                                [Validate Request (Option B)]
                                        |
                                        v (valid)
                                [Queue Celery Task]
                                        |
                                        v
                                [Return 202 {job_id}]
                                        |
                                        |
[Celery Worker] <---task queued--------+
      |
      v
[Generate PDF]
      |
      v
[Write Status to Redis: SETEX export_job:{job_id} 3600 JSON]
      |
      v
[Task Complete]

[User] --GET /api/exports/pdf/{job_id}--> [API Endpoint]
                                                |
                                                v
                                        [Read Redis: GET export_job:{job_id}]
                                                |
                                                v
                                        [Return Status JSON or 404]
```

### Export Request Validation (Option B)

```
[User] --POST with JSON--> [FastAPI Endpoint]
                                |
                                v
                        [Pydantic Validation]
                                |
                +---------------+---------------+
                |                               |
                v (invalid type)                v (valid type)
        [Return 422 Unprocessable]      [Custom Validation]
                                                |
                                +---------------+---------------+
                                |                               |
                                v (rule fails)                  v (all pass)
                        [Return 400 with message]       [Queue Task, Return 202]
```

### Re-ID Similarity Analysis (Option D)

```
[Admin] --run script--> [analyze_reid_performance.py]
                                |
                                v
                        [Query PostgreSQL]
                                |
                                v
                        [Load feature_vectors into DataFrame]
                                |
                                v
                        [Compute pairwise similarities]
                                |
                                v
                        [Generate histogram visualization]
                                |
                                v
                        [Save plot to docs/reid_analysis.png]

[Admin] --run script--> [test_reid_thresholds.py --thresholds 0.70,0.65,0.60,0.55]
                                |
                                v
                        [For each threshold]
                                |
                                v
                        [Apply threshold in-memory]
                                |
                                v
                        [Calculate assignment_rate]
                                |
                                v
                        [Print comparison table]
                                |
                                v
                        [Recommend optimal threshold]
```

---

## Constraints & Validation

### Redis Job Status
- **Uniqueness**: job_id (Celery task_id) is UUID, guaranteed unique
- **TTL**: Exactly 3600 seconds (1 hour), not configurable per-job
- **Size**: JSON typically <1KB, Redis supports up to 512MB (no practical limit)
- **Concurrency**: SETEX is atomic, no race conditions on write

### Export Request
- **Type Safety**: Pydantic enforces date types (rejects "2024-13-32")
- **Range Limits**: 365 days maximum (prevents DoS via large date ranges)
- **Enum Safety**: group_by limited to 3 values (prevents typos like "daily")
- **Temporal Logic**: Cannot request future data (prevents confusion)

### Re-ID Similarity
- **Read-Only**: Analysis scripts never write to detections table
- **Feature Vector**: Must be L2-normalized 512-dim vector (validated during Re-ID)
- **Similarity Range**: Cosine similarity always 0.0-1.0 (by mathematical definition)
- **Classification Filter**: Only analyze deer classes (ignore cattle, pigs, raccoons)

---

## Performance Considerations

### Redis Operations
- **Read Latency**: <1ms for GET operation (in-memory)
- **Write Latency**: <1ms for SETEX operation
- **Memory Usage**: ~1KB per job * max concurrent jobs (<1MB total)
- **Network**: Redis and worker in same Docker network (no external latency)

### Validation Performance
- **Pydantic Overhead**: <1ms for type validation
- **Custom Validation**: <1ms for date comparisons
- **Total Latency**: <5ms added to request (target: <100ms total)

### Re-ID Analysis
- **Query Time**: ~2 seconds to load 11,570 feature vectors from PostgreSQL
- **Similarity Computation**: ~30 seconds for pairwise matrix (11,570 x 20)
- **Visualization**: ~5 seconds to generate histogram
- **Total Runtime**: <5 minutes for complete analysis (meets target)

---

## Security & Privacy

### Export Job Status
- **Exposure Risk**: LOW
  - job_id is UUID (not guessable)
  - Redis not exposed outside Docker network
  - No authentication required (job_id acts as capability token)

### Export Request
- **Injection Risk**: LOW
  - Pydantic validates types (prevents SQL injection via date fields)
  - group_by enum prevents code injection
  - No user input passed to shell commands

### Re-ID Analysis
- **Data Exposure**: NONE
  - Scripts run in worker container (isolated)
  - Output visualizations contain no PII
  - Analysis results are aggregate statistics only

---

## Migration & Compatibility

### Schema Changes
- **Option A**: NONE (Redis is new storage, no DB migration)
- **Option B**: NONE (validation only, no schema changes)
- **Option D**: NONE (read-only analysis, no schema changes)

### Backward Compatibility
- **Export Endpoints**: Existing requests continue to work (validation adds rejection cases)
- **Worker Tasks**: Must update to write Redis, but old behavior still works (just no status tracking)
- **Re-ID Processing**: Analysis scripts don't affect Re-ID pipeline (read-only)

### Rollback Plan
- **Option A**: Remove Redis status updates, revert API to in-memory state (loses status tracking)
- **Option B**: Remove validation logic, revert to old endpoint code (loses validation)
- **Option D**: Delete analysis scripts (no rollback needed, read-only)

---

## Testing Strategy

### Export Job Status
- **Unit Tests**: Mock Redis client, verify SETEX calls with correct TTL
- **Integration Tests**: Create real job, verify status transitions, verify expiry after 1 hour
- **Error Tests**: Simulate Redis connection failure, verify graceful degradation

### Export Request Validation
- **Unit Tests**: Test each validation rule independently with boundary cases
- **Integration Tests**: Submit invalid requests via API, verify 400 responses with correct messages
- **Regression Tests**: Submit previously valid requests, verify they still work

### Re-ID Analysis
- **Unit Tests**: Test similarity calculation with known vectors
- **Integration Tests**: Run on sample dataset (100 detections), verify metrics calculation
- **Accuracy Tests**: Manually validate sample assignments at different thresholds

---

**Data Model Status**: COMPLETE - Ready for implementation
